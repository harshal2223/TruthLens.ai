// AI Service integrated with OpenAI GPT-4
export interface AIAnalysisResult {
  overallScore: number;
  claims: Array<{
    text: string;
    verdict: 'verified' | 'disputed' | 'needs-review';
    confidence: number;
    sources: string[];
    explanation: string;
  }>;
  sources: Array<{
    name: string;
    url: string;
    credibility: number;
    type: 'government' | 'academic' | 'news' | 'organization';
  }>;
  suggestions: string[];
  timeline: Array<{
    date: string;
    event: string;
    source: string;
  }>;
}

export interface UserQueryResult {
  query: string;
  verdict: 'true' | 'false' | 'mixed' | 'unverified';
  confidence: number;
  explanation: string;
  sources: string[];
  relatedClaims: string[];
}

class AIService {
  private apiKey: string;
  private baseUrl: string;

  constructor() {
    this.baseUrl = 'https://api.openai.com/v1';
    this.apiKey = process.env.OPENAI_API_KEY || '';
    
    if (!this.apiKey) {
      console.warn('‚ö†Ô∏è OpenAI API key not found. Using demo mode.');
    }
  }

  // Analyze article content with GPT-4
  async analyzeArticle(content: string, title: string): Promise<AIAnalysisResult> {
    if (!this.apiKey) {
      console.log('üîÑ Using demo mode - add OPENAI_API_KEY to .env.local for real AI');
      return this.getImprovedMockAnalysis(content, title);
    }

    try {
      const prompt = `
You are an expert fact-checker. Analyze this article and provide a detailed fact-check report.

ARTICLE TITLE: ${title}

ARTICLE CONTENT: ${content}

Please analyze this article and respond with a JSON object containing:
1. overallScore (0-100): Overall credibility score
2. claims: Array of specific claims found with verdicts (verified/disputed/needs-review)
3. sources: Credible sources that should be referenced
4. suggestions: Recommendations for improving the article

Focus on:
- Factual accuracy of specific claims
- Source credibility and attribution
- Scientific accuracy where applicable
- Potential bias or misinformation

Respond ONLY with valid JSON matching this structure:
{
  "overallScore": number,
  "claims": [{"text": string, "verdict": string, "confidence": number, "sources": [string], "explanation": string}],
  "sources": [{"name": string, "url": string, "credibility": number, "type": string}],
  "suggestions": [string],
  "timeline": [{"date": string, "event": string, "source": string}]
}`;

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: 'gpt-4',
          messages: [
            {
              role: 'system',
              content: 'You are a professional fact-checker and misinformation expert. Provide accurate, unbiased analysis with proper source attribution.'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: 0.3,
          max_tokens: 2000
        }),
      });

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      const aiResponse = data.choices[0].message.content;
      
      try {
        return JSON.parse(aiResponse);
      } catch (parseError) {
        console.error('Failed to parse AI response:', parseError);
        return this.getImprovedMockAnalysis(content, title);
      }

    } catch (error) {
      console.error('OpenAI Analysis Error:', error);
      return this.getImprovedMockAnalysis(content, title);
    }
  }

  // Process user queries with GPT-4
  async processUserQuery(query: string, context?: string): Promise<UserQueryResult> {
    if (!this.apiKey) {
      console.log('üîÑ Using demo mode - add OPENAI_API_KEY to .env.local for real AI');
      return this.getImprovedMockQueryResult(query);
    }

    try {
      const prompt = `
You are an expert fact-checker. A user has asked: "${query}"

${context ? `CONTEXT: ${context}` : ''}

Please fact-check this claim and respond with a JSON object containing:
1. verdict: 'true', 'false', 'mixed', or 'unverified'
2. confidence: 0-100 confidence score
3. explanation: Clear explanation of your verdict
4. sources: Credible sources that support your analysis
5. relatedClaims: Related claims that might be relevant

Be thorough, accurate, and cite credible sources. If the claim cannot be verified, mark it as 'unverified'.

Respond ONLY with valid JSON:
{
  "query": "${query}",
  "verdict": string,
  "confidence": number,
  "explanation": string,
  "sources": [string],
  "relatedClaims": [string]
}`;

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: 'gpt-4',
          messages: [
            {
              role: 'system',
              content: 'You are a professional fact-checker. Provide accurate, evidence-based analysis with proper source attribution. Be conservative with confidence scores and always cite credible sources.'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: 0.2,
          max_tokens: 1000
        }),
      });

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      const aiResponse = data.choices[0].message.content;
      
      try {
        return JSON.parse(aiResponse);
      } catch (parseError) {
        console.error('Failed to parse AI response:', parseError);
        return this.getImprovedMockQueryResult(query);
      }

    } catch (error) {
      console.error('OpenAI Query Error:', error);
      return this.getImprovedMockQueryResult(query);
    }
  }

  // Improved mock analysis with better logic (fallback)
  private getImprovedMockAnalysis(content: string, title: string): AIAnalysisResult {
    const hasScientificTerms = /climate|temperature|study|research|data|analysis/i.test(content + title);
    const hasNumbers = /\d+(\.\d+)?%|\d+¬∞C|\d+ years?/g.test(content + title);
    const hasSourceMentions = /according to|study shows|research indicates|report states/i.test(content);
    
    let baseScore = 70;
    if (hasScientificTerms) baseScore += 10;
    if (hasNumbers) baseScore += 10;
    if (hasSourceMentions) baseScore += 10;
    
    const overallScore = Math.min(95, baseScore);

    return {
      overallScore,
      claims: [
        {
          text: "Article contains verifiable scientific data and references",
          verdict: hasScientificTerms && hasNumbers ? 'verified' : 'needs-review',
          confidence: hasScientificTerms && hasNumbers ? 88 : 65,
          sources: hasScientificTerms ? ['Scientific Literature', 'Research Databases'] : ['General Sources'],
          explanation: hasScientificTerms 
            ? 'This claim is supported by scientific terminology and data references in the content.'
            : 'This content needs additional verification from scientific sources.'
        }
      ],
      sources: hasScientificTerms ? [
        { name: 'Scientific Research Database', url: 'https://scholar.google.com', credibility: 92, type: 'academic' },
        { name: 'Government Climate Data', url: 'https://climate.gov', credibility: 95, type: 'government' }
      ] : [
        { name: 'General News Sources', url: 'https://reuters.com', credibility: 78, type: 'news' }
      ],
      suggestions: [
        hasSourceMentions ? 'Content shows good source attribution' : 'Consider adding more source citations',
        hasNumbers ? 'Numerical data enhances credibility' : 'Adding specific statistics would strengthen claims'
      ],
      timeline: [
        { date: '2024', event: 'Content analysis performed', source: 'AI System' },
        { date: new Date().getFullYear().toString(), event: 'Verification completed', source: 'TruthLens' }
      ]
    };
  }

  // Improved mock query results (fallback)
  private getImprovedMockQueryResult(query: string): UserQueryResult {
    const lowerQuery = query.toLowerCase();
    
    let verdict: 'true' | 'false' | 'mixed' | 'unverified' = 'unverified';
    let confidence = 50;
    let explanation = 'This claim requires verification from authoritative sources.';
    let sources = ['Verification needed'];

    // Climate-related facts
    if (lowerQuery.includes('climate') && lowerQuery.includes('temperature')) {
      if (lowerQuery.includes('1.1') || lowerQuery.includes('increase')) {
        verdict = 'true';
        confidence = 94;
        explanation = 'Global average temperature has indeed increased by approximately 1.1¬∞C since pre-industrial times, according to multiple climate research organizations.';
        sources = ['IPCC Reports', 'NASA Climate Data', 'NOAA Temperature Records'];
      }
    }
    
    // Renewable energy facts
    else if (lowerQuery.includes('renewable') && lowerQuery.includes('energy')) {
      if (lowerQuery.includes('30%') || lowerQuery.includes('percent')) {
        verdict = 'mixed';
        confidence = 78;
        explanation = 'Renewable energy percentages vary by region and measurement method. Globally, renewables account for about 30% of electricity generation, but this varies significantly by country.';
        sources = ['IEA Energy Statistics', 'IRENA Global Reports'];
      }
    }
    
    // Brain energy consumption
    else if (lowerQuery.includes('brain') && lowerQuery.includes('20%')) {
      verdict = 'true';
      confidence = 92;
      explanation = 'The human brain does consume approximately 20% of the body\'s total energy despite being only about 2% of body weight. This is well-established in neuroscience research.';
      sources = ['Neuroscience Research', 'Medical Literature', 'Scientific Studies'];
    }

    return {
      query,
      verdict,
      confidence,
      explanation,
      sources,
      relatedClaims: this.getRelatedClaims(lowerQuery)
    };
  }

  private getRelatedClaims(query: string): string[] {
    if (query.includes('climate')) {
      return ['Global warming trends', 'Carbon emission levels', 'Sea level rise data'];
    } else if (query.includes('energy')) {
      return ['Solar power capacity', 'Wind energy growth', 'Battery technology advances'];
    } else if (query.includes('health') || query.includes('brain')) {
      return ['Human metabolism facts', 'Organ energy consumption', 'Neurological research'];
    }
    return ['Related fact-checks available', 'Similar claims analyzed'];
  }
}

export const aiService = new AIService();